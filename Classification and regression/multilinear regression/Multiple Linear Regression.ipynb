{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'><h1>Assignment 3: \"Gaurav Raut 2038584/h1></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HelpEase\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "C:\\Users\\HelpEase\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:451: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
      "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Multiple Linear Regression\n",
    "\n",
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Importing the dataset\n",
    "dataset = pd.read_csv('50_Startups.csv')\n",
    "X = dataset.iloc[:, :-1].values\n",
    "y = dataset.iloc[:, 4].values\n",
    "\n",
    "# Encoding categorical data\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "labelencoder = LabelEncoder()\n",
    "X[:, 3] = labelencoder.fit_transform(X[:, 3])\n",
    "onehotencoder = OneHotEncoder(categorical_features = [3])\n",
    "X = onehotencoder.fit_transform(X).toarray()\n",
    "\n",
    "# Avoiding the Dummy Variable Trap\n",
    "X = X[:, 1:]\n",
    "\n",
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Explanation of the libraries that are imported for various purposes. \n",
    "    \n",
    "    Numpy: Numpy is an universally useful cluster preparing bundle.It gives an elite multidimensional array objects, and tools for working with these arrays. It is the major bundle for logical registering with Python.Other than its undeniable logical uses, Numpy can likewise be utilized as a proficient multi-dimensional holder of nonexclusive information.\n",
    "\n",
    "    Pandas: Pandas is an opensource library that permits one to perform information control in Python. Pandas library is based over Numpy, which means Pandas needs Numpy to work. Pandas give a simple method to make, control and wrangle the information.\n",
    "\n",
    "    Matplotlib: Matplotlib is a Python 2D plotting library which produces publication quality figures in a variety of hardcopy formats and interactive environments across platforms.\n",
    "    \n",
    "# Importing the dataset\n",
    "Dataset.iloc[] method is used when a data set's index label is something else than 0, 1, 2, 3 .... n numerical or when the index label is unknown to the user.\n",
    "\n",
    "# Encoding categorical data\n",
    "One hot encryption is to transform each group into a new column, assigning the column to a value of 1 or 0 (True / False). This does not benefit from the excessive weighting of a number but the downside is that more columns are applied to the data set.\n",
    "The use of a technique known as mark encoding is another way to represent categorical values. Increasing value is simply translated into a number by the Label Encoding column.\n",
    "\n",
    "# Avoiding the Dummy Variable trap\n",
    "Also known as indicator variables, dummy variables take discrete values such as 1 or 0, which indicate the existence or absence of a specific group.\n",
    "\n",
    "# Splitting the dataset into the Training set and Test set\n",
    "random_state is used for random number generator initialization in train_test_split. Since we can actually split a dataset in different ways, we are able to use the approach with the same data set many times and always get the same results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[     0.        1.   165349.2  136897.8  471784.1 ]\n",
      " [     0.        0.   162597.7  151377.59 443898.53]\n",
      " [     1.        0.   153441.51 101145.55 407934.54]\n",
      " [     0.        1.   144372.41 118671.85 383199.62]\n",
      " [     1.        0.   142107.34  91391.77 366168.42]\n",
      " [     0.        1.   131876.9   99814.71 362861.36]\n",
      " [     0.        0.   134615.46 147198.87 127716.82]\n",
      " [     1.        0.   130298.13 145530.06 323876.68]\n",
      " [     0.        1.   120542.52 148718.95 311613.29]\n",
      " [     0.        0.   123334.88 108679.17 304981.62]\n",
      " [     1.        0.   101913.08 110594.11 229160.95]\n",
      " [     0.        0.   100671.96  91790.61 249744.55]\n",
      " [     1.        0.    93863.75 127320.38 249839.44]\n",
      " [     0.        0.    91992.39 135495.07 252664.93]\n",
      " [     1.        0.   119943.24 156547.42 256512.92]\n",
      " [     0.        1.   114523.61 122616.84 261776.23]\n",
      " [     0.        0.    78013.11 121597.55 264346.06]\n",
      " [     0.        1.    94657.16 145077.58 282574.31]\n",
      " [     1.        0.    91749.16 114175.79 294919.57]\n",
      " [     0.        1.    86419.7  153514.11      0.  ]\n",
      " [     0.        0.    76253.86 113867.3  298664.47]\n",
      " [     0.        1.    78389.47 153773.43 299737.29]\n",
      " [     1.        0.    73994.56 122782.75 303319.26]\n",
      " [     1.        0.    67532.53 105751.03 304768.73]\n",
      " [     0.        1.    77044.01  99281.34 140574.81]\n",
      " [     0.        0.    64664.71 139553.16 137962.62]\n",
      " [     1.        0.    75328.87 144135.98 134050.07]\n",
      " [     0.        1.    72107.6  127864.55 353183.81]\n",
      " [     1.        0.    66051.52 182645.56 118148.2 ]\n",
      " [     0.        1.    65605.48 153032.06 107138.38]\n",
      " [     1.        0.    61994.48 115641.28  91131.24]\n",
      " [     0.        1.    61136.38 152701.92  88218.23]\n",
      " [     0.        0.    63408.86 129219.61  46085.25]\n",
      " [     1.        0.    55493.95 103057.49 214634.81]\n",
      " [     0.        0.    46426.07 157693.92 210797.67]\n",
      " [     0.        1.    46014.02  85047.44 205517.64]\n",
      " [     1.        0.    28663.76 127056.21 201126.82]\n",
      " [     0.        0.    44069.95  51283.14 197029.42]\n",
      " [     0.        1.    20229.59  65947.93 185265.1 ]\n",
      " [     0.        0.    38558.51  82982.09 174999.3 ]\n",
      " [     0.        0.    28754.33 118546.05 172795.67]\n",
      " [     1.        0.    27892.92  84710.77 164470.71]\n",
      " [     0.        0.    23640.93  96189.63 148001.11]\n",
      " [     0.        1.    15505.73 127382.3   35534.17]\n",
      " [     0.        0.    22177.74 154806.14  28334.72]\n",
      " [     0.        1.     1000.23 124153.04   1903.93]\n",
      " [     1.        0.     1315.46 115816.21 297114.46]\n",
      " [     0.        0.        0.   135426.92      0.  ]\n",
      " [     0.        1.      542.05  51743.15      0.  ]\n",
      " [     0.        0.        0.   116983.8   45173.06]]\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(suppress = True)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting Multiple Linear Regression to the Training set\n",
    "from sklearn.linear_model import LinearRegression\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Fitting Multiple Linear Regression to the Training set\n",
    "It is extremely simple to implement linear regression models with Scikit-Learn. You really need to import, instant, and call the fit(),along with our training details, the LinearRegression class. This is as simple as it is to train our data with a machine learning library.\n",
    "\n",
    "# Predicting the Test set results\n",
    "Assess the model as to how the effects based on the test data are predicted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([103015.20159796, 132582.27760815, 132447.73845175,  71976.09851258,\n",
       "       178537.48221056, 116161.24230166,  67851.69209676,  98791.73374687,\n",
       "       113969.43533013, 167921.06569551])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([103282.38, 144259.4 , 146121.95,  77798.83, 191050.39, 105008.31,\n",
       "        81229.06,  97483.56, 110352.25, 166187.94])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
